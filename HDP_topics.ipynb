{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HDP_topics",
      "provenance": [],
      "authorship_tag": "ABX9TyNbL3MsUzZRUv3viDH0clbz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monu322/LDA_Classification/blob/main/HDP_topics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "kZsXsmloXjzL",
        "outputId": "b6e14c2d-53f1-4571-d0cb-c39e2bd89200"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a5/15a0da6b0150b8b68610cc78af80364a80a9a4c8b6dd5ee549b8989d4b60/pyLDAvis-3.3.1.tar.gz (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 11.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (54.2.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting pandas>=1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/51/48f3fc47c4e2144da2806dfb6629c4dd1fa3d5a143f9652b141e979a8ca9/pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9MB 46.0MB/s \n",
            "\u001b[?25hCollecting numpy>=1.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/ef/8967d406f3f85018ceb5efab50431e901683188f1741ceb053efcab26c87/numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 269kB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (1.1.1)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-cp37-none-any.whl size=136870 sha256=aaa03920a897be7ac8cdd0864c1acf2d6b5fc9a1bf8098b37bccd59a297fe6f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/9c/fc/c6e00689d35c82cf96a8adc70edfe7ba7904374fdac3240ac2\n",
            "Successfully built pyLDAvis\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, pandas, funcy, pyLDAvis\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "Successfully installed funcy-1.15 numpy-1.20.2 pandas-1.2.4 pyLDAvis-3.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRLgHcv2XFyW",
        "outputId": "6020e843-dc6b-4db0-dee2-fe1dc93fe00e"
      },
      "source": [
        "import pickle\n",
        "import gensim\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import nltk; nltk.download('stopwords')\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import re\n",
        "import warnings\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:169: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:286: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:858: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:1094: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:1120: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, positive=False):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:1349: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:1590: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py:1723: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  EPS = np.finfo(np.float).eps\n",
            "/usr/local/lib/python3.7/dist-packages/jsonschema/compat.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import MutableMapping, Sequence  # noqa\n",
            "/usr/local/lib/python3.7/dist-packages/jsonschema/compat.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import MutableMapping, Sequence  # noqa\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/decorators.py:70: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
            "  formatvalue=lambda value: \"\")[1:-1]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype=np.int):\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/io/matlab/mio5.py:98: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from .mio5_utils import VarReader5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "_iYoxxTZXPuw",
        "outputId": "a0d12490-812f-416e-cbd2-ffc9de1e5b77"
      },
      "source": [
        "df = pd.read_csv('yelp.csv')\n",
        "df['text_len'] = df['text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>date</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>user_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
              "      <td>2011-01-26</td>\n",
              "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
              "      <td>5</td>\n",
              "      <td>My wife took me here on my birthday for breakf...</td>\n",
              "      <td>review</td>\n",
              "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
              "      <td>2011-07-27</td>\n",
              "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
              "      <td>5</td>\n",
              "      <td>I have no idea why some people give bad review...</td>\n",
              "      <td>review</td>\n",
              "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
              "      <td>2012-06-14</td>\n",
              "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
              "      <td>4</td>\n",
              "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
              "      <td>review</td>\n",
              "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
              "      <td>2010-05-27</td>\n",
              "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
              "      <td>5</td>\n",
              "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
              "      <td>review</td>\n",
              "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
              "      <td>2012-01-05</td>\n",
              "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
              "      <td>5</td>\n",
              "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
              "      <td>review</td>\n",
              "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id        date  ... funny  text_len\n",
              "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  ...     0       155\n",
              "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  ...     0       257\n",
              "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  ...     0        16\n",
              "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  ...     0        76\n",
              "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  ...     0        86\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkK9GOQCXdOI",
        "outputId": "a5d64c3e-cd8f-4a7c-b8eb-8d27cdc5d68e"
      },
      "source": [
        "rev_train = df[df.stars != 3.0]\n",
        "print('Number of reviews: ', len(rev_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews:  8539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzWPlAdsYBv4",
        "outputId": "e618778c-687c-4d75-d629-c8316c4a93ae"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def strip_newline(series):\n",
        "    return [review.replace('\\n','') for review in series]\n",
        "\n",
        "rev_train['text'] = strip_newline(rev_train.text)\n",
        "rev_train.text[21:22].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"I love this place! I have been coming here for ages.My favorites: Elsa's Chicken sandwich, any of their burgers, dragon chicken wings, china's little chicken sandwich, and the hot pepper chicken sandwich. The atmosphere is always fun and the art they display is very abstract but totally cool!\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nElLVektZBc3",
        "outputId": "f2ab1ecf-3b49-4fb9-94bc-7b0d3bbd53a2"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\n",
        "words_tr = list(sent_to_words(rev_train.text))\n",
        "\n",
        "words_tr[21][:10]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['love',\n",
              " 'this',\n",
              " 'place',\n",
              " 'have',\n",
              " 'been',\n",
              " 'coming',\n",
              " 'here',\n",
              " 'for',\n",
              " 'ages',\n",
              " 'my']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_-WVR9cZOZB",
        "outputId": "3cdb216c-4aee-49d6-d110-b75d03645e4d"
      },
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "words_tr = remove_stopwords(words_tr)\n",
        "\n",
        "def bigrams(words, bi_min=15, tri_min=10):\n",
        "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
        "    trigram = gensim.models.Phrases(bigram[words], min_count = tri_min)\n",
        "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "    return bigram_mod, trigram_mod\n",
        "\n",
        "bigram_tr, trigram_tr = bigrams(words_tr)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V67hLuZ5aZz_",
        "outputId": "135fc11e-7269-4ac0-e48b-4cf71b53d94a"
      },
      "source": [
        "print(trigram_tr[bigram_tr[words_tr[0]]][:200])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['wife', 'took', 'birthday', 'breakfast', 'excellent', 'weather', 'perfect', 'made', 'sitting_outside', 'overlooking', 'grounds', 'absolute', 'pleasure', 'waitress', 'excellent', 'food', 'arrived', 'quickly', 'semi', 'busy', 'saturday_morning', 'looked_like', 'place', 'fills', 'pretty_quickly', 'earlier', 'get', 'better', 'favor', 'get', 'bloody_mary', 'phenomenal', 'simply', 'best_ever', 'pretty_sure', 'use', 'ingredients', 'garden', 'blend', 'fresh', 'order', 'amazing', 'everything_menu', 'looks', 'excellent', 'white', 'truffle', 'scrambled_eggs', 'vegetable', 'skillet', 'tasty', 'delicious', 'came', 'pieces', 'griddled', 'bread', 'amazing', 'absolutely', 'made', 'meal', 'complete', 'best', 'toast', 'ever', 'anyway', 'wait_go_back']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSlcWCo8ayt_",
        "outputId": "1bf08847-d4fd-41bf-ab9f-4dd447a8f638"
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN','ADJ','VERB','ADV']):\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out\n",
        "\n",
        "trigrams_tr = [trigram_tr[bigram_tr[review]] for review in words_tr]\n",
        "\n",
        "lemma_lg = lemmatization(trigrams_tr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:126: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NYW3GZkcRjS",
        "outputId": "79d74711-2f26-458a-bb12-482cf8cedb29"
      },
      "source": [
        "lemma_lg[0][:20]\n",
        "\n",
        "id2word_lg = gensim.corpora.Dictionary(lemma_lg)\n",
        "id2word_lg.filter_extremes(no_below=10, no_above=0.35)\n",
        "id2word_lg.compactify()\n",
        "id2word_lg.save('train_dict_lg')\n",
        "corpus_lg = [id2word_lg.doc2bow(text) for text in lemma_lg]\n",
        "\n",
        "corpus_lg[22][:10]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(9, 1),\n",
              " (13, 1),\n",
              " (14, 1),\n",
              " (20, 2),\n",
              " (55, 1),\n",
              " (59, 1),\n",
              " (63, 1),\n",
              " (70, 1),\n",
              " (86, 1),\n",
              " (88, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0TKeAKlep0H",
        "outputId": "4f8621e4-4870-4a23-997e-1e79715e0ddb"
      },
      "source": [
        "[(id2word_lg[id], freq) for id, freq in corpus_lg[0]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('absolute', 1),\n",
              " ('absolutely', 1),\n",
              " ('amaze', 1),\n",
              " ('amazing', 1),\n",
              " ('arrive', 1),\n",
              " ('birthday', 1),\n",
              " ('blend', 1),\n",
              " ('bread', 1),\n",
              " ('breakfast', 1),\n",
              " ('busy', 1),\n",
              " ('come', 1),\n",
              " ('complete', 1),\n",
              " ('earlier', 1),\n",
              " ('ever', 1),\n",
              " ('excellent', 3),\n",
              " ('favor', 1),\n",
              " ('fill', 1),\n",
              " ('food', 1),\n",
              " ('fresh', 1),\n",
              " ('garden', 1),\n",
              " ('get', 1),\n",
              " ('ground', 1),\n",
              " ('ingredient', 1),\n",
              " ('look', 1),\n",
              " ('make', 2),\n",
              " ('meal', 1),\n",
              " ('order', 1),\n",
              " ('perfect', 1),\n",
              " ('phenomenal', 1),\n",
              " ('piece', 1),\n",
              " ('pleasure', 1),\n",
              " ('quickly', 1),\n",
              " ('semi', 1),\n",
              " ('simply', 1),\n",
              " ('skillet', 1),\n",
              " ('take', 1),\n",
              " ('tasty', 1),\n",
              " ('toast', 1),\n",
              " ('use', 1),\n",
              " ('vegetable', 1),\n",
              " ('waitress', 1),\n",
              " ('weather', 1),\n",
              " ('well', 1),\n",
              " ('white', 1),\n",
              " ('wife', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwCiKoqGZSjt",
        "outputId": "de326da9-45fd-4692-9291-da33933b353a"
      },
      "source": [
        "from gensim.models import HdpModel\n",
        "hdp = HdpModel(corpus_lg, id2word_lg, chunksize=10000)\n",
        "\n",
        "len(hdp.print_topics())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF2bfsu4fYc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98fbe808-4e77-41f9-a3e4-a86e1e3c0f41"
      },
      "source": [
        "hdp.print_topics(num_topics=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.003*cream + 0.002*item + 0.002*anti + 0.002*absolutely + 0.002*critical + 0.002*cabbage + 0.002*trendy + 0.002*english + 0.002*sitting + 0.002*thought_would'),\n",
              " (1,\n",
              "  '0.002*address + 0.002*tattoo + 0.002*utensil + 0.002*towner + 0.002*suit + 0.002*fortunately + 0.002*tooth + 0.002*sexy + 0.002*cherry + 0.002*marshmallow'),\n",
              " (2,\n",
              "  '0.002*fair + 0.002*increase + 0.002*choose + 0.002*chewy + 0.002*spicy + 0.002*decline + 0.002*minimal + 0.002*soda + 0.002*taco + 0.002*meaning'),\n",
              " (3,\n",
              "  '0.003*decadent + 0.002*topic + 0.002*speaker + 0.002*darn + 0.002*considering + 0.002*colorful + 0.002*service + 0.002*land + 0.002*cardboard + 0.002*couch'),\n",
              " (4,\n",
              "  '0.003*adequate + 0.002*san + 0.002*desire + 0.002*upstairs + 0.002*tail + 0.002*goodness + 0.002*dipping_sauce + 0.002*chase + 0.002*veggie + 0.002*moment'),\n",
              " (5,\n",
              "  '0.003*desire + 0.002*shopping + 0.002*dust + 0.002*pretzel + 0.002*trash + 0.002*condition + 0.002*stand + 0.002*spinach + 0.002*print + 0.002*blood'),\n",
              " (6,\n",
              "  '0.002*everywhere + 0.002*cheeseburger + 0.002*opening + 0.002*cashew + 0.002*enjoy_meal + 0.002*surprised + 0.002*drizzle + 0.002*band + 0.002*copper + 0.002*groom'),\n",
              " (7,\n",
              "  '0.002*vegetable + 0.002*chunk + 0.002*farm + 0.002*unfortunate + 0.002*haircut + 0.002*fool + 0.002*sublime + 0.002*text + 0.002*live_music + 0.002*cheesesteak'),\n",
              " (8,\n",
              "  '0.002*warranty + 0.002*club + 0.002*girl + 0.002*believe + 0.002*occupy + 0.002*crap + 0.002*mom + 0.002*waste_time + 0.002*sale + 0.002*something_new'),\n",
              " (9,\n",
              "  '0.003*phenomenal + 0.002*coffee_shop + 0.002*extensive + 0.002*beet + 0.002*offend + 0.002*wonderfully + 0.002*homeless + 0.002*allow + 0.002*engage + 0.002*hop'),\n",
              " (10,\n",
              "  '0.003*western + 0.002*flaky + 0.002*damn + 0.002*freakin + 0.002*tamale + 0.002*paint + 0.002*expose + 0.002*snooty + 0.002*delight + 0.002*bonus'),\n",
              " (11,\n",
              "  '0.002*wallet + 0.002*district + 0.002*unhappy + 0.002*execution + 0.002*lift + 0.002*keep_coming_back + 0.002*force + 0.002*source + 0.002*owner + 0.002*run'),\n",
              " (12,\n",
              "  '0.003*spending + 0.002*stir + 0.002*staple + 0.002*afford + 0.002*sure + 0.002*period + 0.002*drunk + 0.002*solely + 0.002*accent + 0.001*milkshake'),\n",
              " (13,\n",
              "  '0.002*reserve + 0.002*horribly + 0.002*wrap + 0.002*banana + 0.002*heavenly + 0.002*plant + 0.002*grill + 0.002*grocery + 0.002*connection + 0.002*lift'),\n",
              " (14,\n",
              "  '0.003*many_time + 0.002*speak + 0.002*layout + 0.002*therefore + 0.002*peace + 0.002*mall + 0.002*preserve + 0.002*french_frie + 0.002*training + 0.002*swim'),\n",
              " (15,\n",
              "  '0.002*wait_come_back + 0.002*train + 0.002*blacken + 0.002*stranger + 0.002*vehicle + 0.002*ensure + 0.002*soft + 0.002*fillet + 0.002*espresso + 0.002*knife'),\n",
              " (16,\n",
              "  '0.002*row + 0.002*son + 0.002*high_end + 0.002*gratuity + 0.002*consider + 0.002*moron + 0.002*bacon + 0.002*boot + 0.001*nachos + 0.001*magazine'),\n",
              " (17,\n",
              "  '0.003*divide + 0.002*be + 0.002*product + 0.002*spoil + 0.002*nee + 0.002*surprised + 0.002*session + 0.002*extreme + 0.002*hurry + 0.002*adequate'),\n",
              " (18,\n",
              "  '0.003*pork_belly + 0.002*used + 0.002*membership + 0.002*raspberry + 0.002*border + 0.002*produce + 0.002*sip + 0.002*order + 0.002*downstairs + 0.002*draw'),\n",
              " (19,\n",
              "  '0.002*shoe + 0.002*whenever + 0.002*slight + 0.002*coming_back + 0.002*south + 0.002*grass + 0.002*conveniently + 0.002*reputation + 0.002*proceed + 0.002*daily')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}